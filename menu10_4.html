<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-python.min.js"></script> 
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism.min.css" rel="stylesheet" />    

<button class="copy-btn" onclick="copyCode('source-code')">ğŸ“‹ Copy</button>  
<code id="source-code" class="language-python">
#################  PDF ë‚´ìš© ìš”ì•½í•˜ê¸° ###################
"""
PyPDFLoader
https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/

PyPDFLoader ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ ,
RecursiveCharacterTextSplitter ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•œ í›„,
LangChainì˜ ìš”ì•½ ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ PDF ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì˜ˆì œ.
- Loader â†’ Splitter â†’ LLM â†’ map_reduce
"""

import os
import glob
from typing import List

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain


# ===== ì‚¬ìš©ì ì„¤ì •(ì½”ë“œ ë‚´ì—ì„œ ì§€ì •) =====
TARGET_PATH = "./data/[2025]Pregnancy Outcomes After Transvaginal Radiofrequency Ablation of Leiomyomas.pdf"               # ìš”ì•½í•  PDF íŒŒì¼ ê²½ë¡œ(ë‹¨ì¼ .pdf) ë˜ëŠ” í´ë” ê²½ë¡œ
MODEL_NAME = "gpt-4o-mini"           # OpenAI ëª¨ë¸ëª…
CHUNK_SIZE = 4000                    # ì²­í¬ í¬ê¸°
CHUNK_OVERLAP = 0                    # ì²­í¬ ì˜¤ë²„ë©
SAVE_PATH = "summary.txt"            # ê²°ê³¼ ì €ì¥ ê²½ë¡œ(ì €ì¥í•˜ì§€ ì•Šìœ¼ë ¤ë©´ None)
# =====================================


def load_pdfs(path: str) -> List:
    """
    pathê°€ íŒŒì¼ì´ë©´ ê·¸ íŒŒì¼ë§Œ, í´ë”ë©´ í´ë” ë‚´ì˜ ëª¨ë“  PDFë¥¼ ë¡œë“œí•œë‹¤.
    ê° PDFëŠ” í˜ì´ì§€ ë‹¨ìœ„ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œë˜ë©°, ëª¨ë‘ í•©ì³ ë°˜í™˜í•œë‹¤.
    """
    documents = []

    def load_one(pdf_path: str):
        loader = PyPDFLoader(pdf_path)
        return loader.load()  # í˜ì´ì§€ë³„ Document ë¦¬ìŠ¤íŠ¸

    if os.path.isdir(path):
        pdf_paths = sorted(glob.glob(os.path.join(path, "*.pdf")))
        if not pdf_paths:
            raise FileNotFoundError(f"í´ë” ë‚´ PDF íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆë‹¤: {path}")
        for p in pdf_paths:
            documents.extend(load_one(p))
    else:
        if not os.path.exists(path):
            raise FileNotFoundError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤: {path}")
        if not path.lower().endswith(".pdf"):
            raise ValueError("PDF íŒŒì¼(.pdf) ë˜ëŠ” PDF í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•œë‹¤.")
        documents.extend(load_one(path))

    return documents


def build_chain(api_key: str, model: str = "gpt-4o-mini"):
    """
    temperature=0, max_tokens=3000, map_reduce ì²´ì¸ êµ¬ì„±(map/combined í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í…€)
    """
    llm = ChatOpenAI(
        temperature=0,
        openai_api_key=api_key,
        max_tokens=3000,
        model=model,
        request_timeout=120,
    )

    map_prompt = PromptTemplate(
        template=(
            "Summarize the following PDF chunk. "
            "Focus on *key points, terms, data, and conclusions*. "
            "Keep it concise and factual.\n\n```{text}```"
        ),
        input_variables=["text"],
    )

    combine_prompt = PromptTemplate(
        template=(
            "Combine the following partial summaries of a PDF into a single coherent summary. "
            "Provide a concise summary in 8 to 10 sentences, preserving structure (topic â†’ details â†’ implications). "
            "If the text includes sections or headings, reflect them briefly.\n\n```{text}```"
        ),
        input_variables=["text"],
    )

    chain = load_summarize_chain(
        llm,
        chain_type="map_reduce",
        verbose=False,
        map_prompt=map_prompt,
        combine_prompt=combine_prompt,
    )
    return chain


def summarize_pdf(
    path: str,
    chunk_size: int = 4000,
    chunk_overlap: int = 0,
    model: str = "gpt-4o-mini",
) -> str:
    """
    PDF(ë“¤)ë¥¼ ë¶ˆëŸ¬ì™€ ë¬¸ì„œ ë‹¨ìœ„ë¡œ chunking í›„ map_reduce ìš”ì•½ì„ ìˆ˜í–‰í•œë‹¤.
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise EnvironmentError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šë‹¤.")

    # 1) Load
    documents = load_pdfs(path)

    # 2) Split
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", " ", ""],  # PDF íŠ¹ì„±ìƒ ì¤„ë°”ê¿ˆì„ ë¨¼ì € ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
    )
    chunks = splitter.split_documents(documents)

    # 3) Chain
    chain = build_chain(api_key=api_key, model=model)

    # 4) Summarize
    result = chain.invoke(chunks)
    return result["output_text"]


if __name__ == "__main__":
    summary = summarize_pdf(
        path=TARGET_PATH,
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        model=MODEL_NAME,
    )

    if SAVE_PATH:
        with open(SAVE_PATH, "w", encoding="utf-8") as f:
            f.write(summary)
        print(f"[INFO] ìš”ì•½ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {SAVE_PATH}")
    else:
        print("\n===== PDF Summary =====\n")
        print(summary)


   
</code>
<script>
    function copyCode(elementId) {
        // í•´ë‹¹ ìš”ì†Œì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ê³  ë³µì‚¬í•©ë‹ˆë‹¤.
        var codeElement = document.getElementById(elementId);
        var range = document.createRange();
        range.selectNodeContents(codeElement);
        var selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
    
        try {
            document.execCommand('copy');
        } catch (err) {
            alert('ë³µì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        }
        
        // ì„ íƒ í•´ì œ
        selection.removeAllRanges();
    }
</script>